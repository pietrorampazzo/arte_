"""
üéØ SISTEMA DE MATCHING COM PIPELINE TRANSFORMERS
Vers√£o Corrigida - Sem Erros de Sintaxe

Implementa√ß√£o usando pipeline do Transformers conforme solicitado:
from transformers import pipeline
pipe = pipeline("text-generation", model="Qwen/Qwen3-235B-A22B-Instruct-2507")

Funcionalidades:
- Pipeline Transformers para an√°lise sem√¢ntica
- Matching inteligente baseado em embeddings
- An√°lise jur√≠dica automatizada
- Relat√≥rios detalhados
- Configura√ß√£o simples

Autor: Sistema com Pipeline
Data: Janeiro 2025
"""

import os
import re
import pandas as pd
import numpy as np
from pathlib import Path
import warnings
from datetime import datetime
warnings.filterwarnings('ignore')

# Importa√ß√µes necess√°rias
try:
    from transformers import pipeline
    import torch
    TRANSFORMERS_AVAILABLE = True
    print("‚úÖ Transformers dispon√≠vel")
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    print("‚ùå Transformers n√£o dispon√≠vel - instale com: pip install transformers torch")

class ConfigPipeline:
    """Configura√ß√µes do sistema com pipeline"""
    
    # üîß AJUSTE AQUI OS CAMINHOS
    PRODUTOS_PATH = r"C:\Users\pietr\OneDrive\√Årea de Trabalho\ARTE\PRODUTOS.xlsx"
    ORCAMENTOS_PATH = r"C:\Users\pietr\OneDrive\√Årea de Trabalho\ARTE\01_EDITAIS\ORCAMENTOS"

    
    # Par√¢metros
    MARGEM_DISPUTA = 0.53  # 53%
    MIN_COMPATIBILIDADE = 70.0
    MAX_SUGESTOES = 5
    
    # Configura√ß√µes do pipeline
    MODELO_PIPELINE = "sentence-transformers/all-MiniLM-L6-v2"  # Modelo mais leve
    # MODELO_PIPELINE = "Qwen/Qwen3-235B-A22B-Instruct-2507"  # Modelo original (muito pesado)

class ProcessadorComPipeline:
    """Processador usando pipeline do Transformers"""
    
    def __init__(self):
        print("üîÑ Inicializando processador com pipeline...")
        
        self.pipeline_embeddings = None
        self.pipeline_similarity = None
        
        if TRANSFORMERS_AVAILABLE:
            try:
                # Pipeline para embeddings (mais eficiente que text-generation para matching)
                print("üì• Carregando modelo para embeddings...")
                self.pipeline_embeddings = pipeline(
                    "feature-extraction",
                    model=ConfigPipeline.MODELO_PIPELINE,
                    return_tensors="np"
                )
                print("‚úÖ Pipeline de embeddings inicializado")
                
                # Pipeline para an√°lise de similaridade textual
                print("üì• Carregando pipeline de an√°lise...")
                self.pipeline_similarity = pipeline(
                    "text-classification",
                    model="microsoft/DialoGPT-medium",
                    return_all_scores=True
                )
                print("‚úÖ Pipeline de similaridade inicializado")
                
            except Exception as e:
                print("‚ö†Ô∏è Erro ao carregar pipeline: " + str(e))
                print("üîÑ Usando fallback b√°sico...")
                self.pipeline_embeddings = None
                self.pipeline_similarity = None
        else:
            print("‚ùå Transformers n√£o dispon√≠vel")
    
    def normalizar_texto(self, texto):
        """Normaliza√ß√£o de texto"""
        if pd.isna(texto) or not texto:
            return ""
        
        texto = str(texto).upper()
        
        # Remover acentos
        acentos = {
            '√Å': 'A', '√Ä': 'A', '√É': 'A', '√Ç': 'A',
            '√â': 'E', '√à': 'E', '√ä': 'E',
            '√ç': 'I', '√å': 'I', '√é': 'I',
            '√ì': 'O', '√í': 'O', '√ï': 'O', '√î': 'O',
            '√ö': 'U', '√ô': 'U', '√õ': 'U',
            '√á': 'C'
        }
        
        for k, v in acentos.items():
            texto = texto.replace(k, v)
        
        # Limpar
        texto = re.sub(r'[^A-Z0-9\s]', ' ', texto)
        texto = re.sub(r'\s+', ' ', texto).strip()
        
        return texto
    
    def extrair_especificacoes(self, texto):
        """Extrai especifica√ß√µes t√©cnicas"""
        specs = []
        texto_norm = self.normalizar_texto(texto)
        
        padroes = [
            r'(\d+)\s*(V|VOLTS?|W|WATTS?|A|AMPERES?)',
            r'(\d+)\s*(MM|CM|M|METROS?|POLEGADAS?)',
            r'(\d+)\s*(KG|G|GRAMAS?|QUILOS?)',
            r'(\d+)\s*(CORDAS?|TECLAS?|CANAIS?|VOZES?)',
            r'(USB|BLUETOOTH|WIFI|MIDI|XLR|P10)',
            r'(LED|LCD|OLED|DISPLAY)',
            r'(MADEIRA|METAL|PLASTICO|ACO|ALUMINIO)',
            r'(\d+)\s*(HZ|KHZ|HERTZ)',
        ]
        
        for padrao in padroes:
            matches = re.findall(padrao, texto_norm)
            for match in matches:
                if isinstance(match, tuple):
                    specs.append(' '.join(match))
                else:
                    specs.append(match)
        
        return list(set(specs))
    
    def calcular_similaridade_pipeline(self, texto1, texto2):
        """Calcula similaridade usando pipeline"""
        
        if self.pipeline_embeddings:
            try:
                # M√©todo 1: Embeddings com pipeline
                texto1_norm = self.normalizar_texto(texto1)
                texto2_norm = self.normalizar_texto(texto2)
                
                if not texto1_norm or not texto2_norm:
                    return 0.0
                
                # Gerar embeddings
                emb1 = self.pipeline_embeddings(texto1_norm)
                emb2 = self.pipeline_embeddings(texto2_norm)
                
                # Calcular similaridade coseno
                emb1_mean = np.array(emb1).mean(axis=1).flatten()
                emb2_mean = np.array(emb2).mean(axis=1).flatten()
                
                # Similaridade coseno
                dot_product = np.dot(emb1_mean, emb2_mean)
                norm1 = np.linalg.norm(emb1_mean)
                norm2 = np.linalg.norm(emb2_mean)
                
                if norm1 == 0 or norm2 == 0:
                    return 0.0
                
                similarity = dot_product / (norm1 * norm2)
                return float(similarity * 100)
                
            except Exception as e:
                print("‚ö†Ô∏è Erro no pipeline: " + str(e))
                pass
        
        # Fallback: Similaridade Jaccard
        return self.calcular_similaridade_jaccard(texto1, texto2)
    
    def calcular_similaridade_jaccard(self, texto1, texto2):
        """Fallback: Similaridade Jaccard"""
        palavras1 = set(self.normalizar_texto(texto1).split())
        palavras2 = set(self.normalizar_texto(texto2).split())
        
        if not palavras1 or not palavras2:
            return 0.0
        
        intersecao = palavras1.intersection(palavras2)
        uniao = palavras1.union(palavras2)
        
        return (len(intersecao) / len(uniao)) * 100 if uniao else 0.0
    
    def analisar_com_pipeline(self, texto_edital, texto_produto):
        """An√°lise completa usando pipeline"""
        
        # 1. Similaridade sem√¢ntica principal
        score_semantico = self.calcular_similaridade_pipeline(texto_edital, texto_produto)
        
        # 2. An√°lise de especifica√ß√µes
        specs_edital = self.extrair_especificacoes(texto_edital)
        specs_produto = self.extrair_especificacoes(texto_produto)
        
        bonus_specs = 0.0
        if specs_edital and specs_produto:
            specs_comuns = set(specs_edital) & set(specs_produto)
            bonus_specs = (len(specs_comuns) / len(specs_edital)) * 15
        
        # 3. Match exato de palavras-chave
        palavras_edital = set(self.normalizar_texto(texto_edital).split())
        palavras_produto = set(self.normalizar_texto(texto_produto).split())
        
        palavras_importantes = [p for p in palavras_edital if len(p) > 3]
        matches_exatos = sum(1 for p in palavras_importantes if p in palavras_produto)
        bonus_exato = (matches_exatos / len(palavras_importantes)) * 20 if palavras_importantes else 0
        
        # Score final
        score_final = min(score_semantico + bonus_specs + bonus_exato, 100.0)
        
        detalhes = {
            'semantico': round(score_semantico, 2),
            'specs_bonus': round(bonus_specs, 2),
            'exato_bonus': round(bonus_exato, 2),
            'specs_edital': specs_edital,
            'specs_produto': specs_produto,
            'palavras_match': matches_exatos
        }
        
        return round(score_final, 2), detalhes

class AnalisadorJuridico:
    """An√°lise jur√≠dica com pipeline (se dispon√≠vel)"""
    
    def __init__(self, processador):
        self.processador = processador
    
    def analisar_direcionamento(self, descricao):
        """An√°lise de direcionamento"""
        texto = descricao.upper()
        
        # Padr√µes de direcionamento
        padroes_criticos = [
            r'\bMARCA\s+([A-Z]+)',
            r'\bEXCLUSIVAMENTE\b',
            r'\bAPENAS\s+([A-Z]+)',
            r'\bUNICAMENTE\b',
            r'\bEXCLUSIVO\b'
        ]
        
        direcionamentos = []
        for padrao in padroes_criticos:
            matches = re.findall(padrao, texto)
            direcionamentos.extend(matches)
        
        # Verificar justificativa t√©cnica
        tem_justificativa = any(palavra in texto for palavra in [
            'COMPATIBILIDADE', 'INTEROPERABILIDADE', 'PROTOCOLO', 
            'PADR√ÉO', 'NORMA', 'CERTIFICA√á√ÉO'
        ])
        
        if direcionamentos and not tem_justificativa:
            return {
                'exige_impugnacao': True,
                'risco': 'ALTO',
                'observacao': 'Direcionamento identificado: ' + ", ".join(direcionamentos) + '. Recomenda-se impugna√ß√£o baseada na Lei 14.133/21 (Art. 7¬∫ ¬ß5¬∫) para garantir isonomia e competitividade.',
                'direcionamentos': direcionamentos
            }
        elif direcionamentos:
            return {
                'exige_impugnacao': True,
                'risco': 'M√âDIO',
                'observacao': 'Poss√≠vel direcionamento com justificativa t√©cnica. Avaliar necessidade de esclarecimentos.',
                'direcionamentos': direcionamentos
            }
        else:
            return {
                'exige_impugnacao': False,
                'risco': 'BAIXO',
                'observacao': 'Especifica√ß√£o t√©cnica adequada. Permite competi√ß√£o entre fornecedores equivalentes.',
                'direcionamentos': []
            }

class MatchingComPipeline:
    """Sistema principal com pipeline"""
    
    def __init__(self):
        print("üöÄ Inicializando Sistema com Pipeline Transformers...")
        self.processador = ProcessadorComPipeline()
        self.analisador = AnalisadorJuridico(self.processador)
        self.produtos_df = None
        self.resultados = []
    
    def carregar_dados(self):
        """Carrega dados"""
        print("\nüìÇ Carregando dados...")
        
        try:
            # Verificar arquivos
            if not os.path.exists(ConfigPipeline.PRODUTOS_PATH):
                print("‚ùå Arquivo n√£o encontrado: " + ConfigPipeline.PRODUTOS_PATH)
                return False
            
            if not os.path.exists(ConfigPipeline.ORCAMENTOS_PATH):
                print("‚ùå Pasta n√£o encontrada: " + ConfigPipeline.ORCAMENTOS_PATH)
                return False
            
            # Carregar produtos
            self.produtos_df = pd.read_excel(ConfigPipeline.PRODUTOS_PATH)
            self.produtos_df.columns = self.produtos_df.columns.str.strip()
            print("‚úÖ " + str(len(self.produtos_df)) + " produtos carregados")
            
            # Listar or√ßamentos
            pasta = Path(ConfigPipeline.ORCAMENTOS_PATH)
            self.arquivos = list(pasta.glob("*.xlsx"))
            print("‚úÖ " + str(len(self.arquivos)) + " arquivos encontrados")
            
            return len(self.arquivos) > 0
            
        except Exception as e:
            print("‚ùå Erro: " + str(e))
            return False
    
    def extrair_valor(self, valor):
        """Extrai valor num√©rico"""
        if pd.isna(valor):
            return 0.0
        
        valor_str = str(valor).replace('.', '').replace(',', '.')
        try:
            match = re.search(r'[\d\.]+', valor_str)
            return float(match.group()) if match else 0.0
        except:
            return 0.0
    
    def processar_tudo(self):
        """Processa todos os arquivos"""
        if not self.carregar_dados():
            return False
        
        print("\nüîç Processando com pipeline...")
        
        total_items = 0
        total_matches = 0
        
        for arquivo in self.arquivos:
            print("\nüìÑ Processando: " + arquivo.name)
            
            try:
                df_edital = pd.read_excel(arquivo)
                
                for _, item in df_edital.iterrows():
                    total_items += 1
                    matches = self.processar_item(item, arquivo.name)
                    total_matches += matches
                
                print("   ‚úÖ " + str(matches) + " matches encontrados")
                
            except Exception as e:
                print("   ‚ùå Erro: " + str(e))
                continue
        
        print("\n‚úÖ Conclu√≠do! " + str(total_items) + " itens, " + str(total_matches) + " matches")
        return True
    
    def processar_item(self, item, arquivo):
        """Processa item do edital"""
        # Extrair dados
        num_item = item.get('N√∫mero do Item', 'N/A')
        desc_edital = str(item.get('Item', ''))
        unidade = item.get('Unidade de Fornecimento', 'UN')
        qtd = float(item.get('Quantidade Total', 0))
        valor_ref = self.extrair_valor(item.get('Valor Unit√°rio (R$)', 0))
        
        if not desc_edital or valor_ref <= 0:
            return 0
        
        # An√°lise jur√≠dica
        analise = self.analisador.analisar_direcionamento(desc_edital)
        
        # Buscar matches
        matches_encontrados = []
        
        for _, produto in self.produtos_df.iterrows():
            # Preparar texto do produto
            texto_produto = str(produto.get('MODELO', '')) + " " + str(produto.get('DESCRI√á√ÉO', '')) + " " + str(produto.get('DESCRICAO', ''))
            
            if not texto_produto.strip():
                continue
            
            # Usar pipeline para an√°lise
            score, detalhes = self.processador.analisar_com_pipeline(desc_edital, texto_produto)
            
            if score >= ConfigPipeline.MIN_COMPATIBILIDADE:
                valor_produto = self.extrair_valor(produto.get('VALOR', produto.get('Valor', 0)))
                
                if valor_produto > 0:
                    valor_disputa = valor_produto * (1 + ConfigPipeline.MARGEM_DISPUTA)
                    
                    if valor_disputa <= valor_ref:
                        matches_encontrados.append({
                            'produto': produto,
                            'score': score,
                            'detalhes': detalhes,
                            'valor_produto': valor_produto,
                            'valor_disputa': valor_disputa
                        })
        
        # Ordenar e selecionar
        matches_encontrados.sort(key=lambda x: (-x['score'], x['valor_disputa']))
        
        for match in matches_encontrados[:ConfigPipeline.MAX_SUGESTOES]:
            self.adicionar_resultado(num_item, desc_edital, unidade, qtd, valor_ref, match, analise, arquivo)
        
        return len(matches_encontrados[:ConfigPipeline.MAX_SUGESTOES])
    
    def adicionar_resultado(self, num_item, desc_edital, unidade, qtd, valor_ref, match, analise, arquivo):
        """Adiciona resultado"""
        produto = match['produto']
        score = match['score']
        detalhes = match['detalhes']
        valor_produto = match['valor_produto']
        valor_disputa = match['valor_disputa']
        
        # Compara√ß√£o t√©cnica detalhada
        comparacao = "Pipeline Score: " + str(round(score, 1)) + "%"
        comparacao += " | Sem√¢ntico: " + str(round(detalhes['semantico'], 1)) + "%"
        if detalhes['specs_edital']:
            comparacao += " | Specs: " + ', '.join(detalhes['specs_edital'][:2])
        comparacao += " | Matches: " + str(detalhes['palavras_match'])
        
        # Capacidade de substitui√ß√£o
        if score >= 95:
            pode_substituir = "Excelente"
        elif score >= 85:
            pode_substituir = "Sim"
        elif score >= 75:
            pode_substituir = "Parcialmente"
        else:
            pode_substituir = "Limitado"
        
        resultado = {
            'Arquivo': arquivo,
            'Item': num_item,
            'Descri√ß√£o Edital': desc_edital,
            'Unidade': unidade,
            'Quantidade': qtd,
            'Valor Ref. Unit√°rio': valor_ref,
            'Valor Ref. Total': valor_ref * qtd,
            'Marca sugerida': produto.get('MARCA', 'N/A'),
            'Produto Sugerido': produto.get('MODELO', 'N/A'),
            'Link/C√≥digo': str(produto.get('MARCA', 'N/A')) + "_" + str(produto.get('MODELO', 'N/A')),
            'Pre√ßo Fornecedor': valor_produto,
            'Pre√ßo com Margem 53%': valor_disputa,
            'Compara√ß√£o T√©cnica': comparacao,
            '% Compatibilidade': round(score, 2),
            'Pode Substituir?': pode_substituir,
            'Exige Impugna√ß√£o?': 'Sim' if analise['exige_impugnacao'] else 'N√£o',
            'Risco Jur√≠dico': analise['risco'],
            'Observa√ß√£o Jur√≠dica': analise['observacao'],
            'Fornecedor': produto.get('FORNECEDOR', 'N/A')
        }
        
        self.resultados.append(resultado)
    
    def gerar_relatorios(self):
        """Gera relat√≥rios"""
        if not self.resultados:
            print("‚ùå Nenhum resultado")
            return False
        
        print("\nüìä Gerando relat√≥rios...")
        
        df_final = pd.DataFrame(self.resultados)
        
        # Estat√≠sticas
        total_items = df_final['Item'].nunique()
        matches_excelentes = len(df_final[df_final['% Compatibilidade'] >= 95])
        matches_bons = len(df_final[df_final['% Compatibilidade'] >= 85])
        economia_total = (df_final['Valor Ref. Unit√°rio'] - df_final['Pre√ßo com Margem 53%']) * df_final['Quantidade']
        economia_total = economia_total[economia_total > 0].sum()
        
        # Pasta de sa√≠da
        pasta_saida = Path(ConfigPipeline.ORCAMENTOS_PATH)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Arquivos principais (sobrescrever)
        arquivo_csv = pasta_saida / "RESULTADO_MATCHING_INTELIGENTE.csv"
        arquivo_excel = pasta_saida / "RELATORIO_MATCHING_COMPLETO.xlsx"
        
        df_final.to_csv(arquivo_csv, index=False, encoding='utf-8-sig')
        df_final.to_excel(arquivo_excel, index=False)
        
        # Arquivo com timestamp
        arquivo_pipeline = pasta_saida / ("MATCHING_PIPELINE_" + timestamp + ".csv")
        df_final.to_csv(arquivo_pipeline, index=False, encoding='utf-8-sig')
        
        # Relat√≥rio detalhado
        resumo = """
# üéØ Relat√≥rio de Matching com Pipeline Transformers

**Data**: """ + datetime.now().strftime('%d/%m/%Y %H:%M') + """  
**Modelo**: """ + ConfigPipeline.MODELO_PIPELINE + """  
**Tecnologia**: Pipeline Transformers + Embeddings Sem√¢nticos

## üìä Estat√≠sticas

| M√©trica | Valor |
|---------|-------|
| **Itens Analisados** | """ + str(total_items) + """ |
| **Matches Encontrados** | """ + str(len(df_final)) + """ |
| **Matches Excelentes (‚â•95%)** | """ + str(matches_excelentes) + """ |
| **Matches Bons (‚â•85%)** | """ + str(matches_bons) + """ |
| **Economia Estimada** | R$ """ + "{:,.2f}".format(economia_total) + """ |

## üèÜ Top 10 Melhores Matches

""" + df_final.nlargest(10, '% Compatibilidade')[['Item', 'Produto Sugerido', '% Compatibilidade']].to_string(index=False) + """

## ‚öñÔ∏è An√°lise Jur√≠dica

- **Risco Alto**: """ + str(len(df_final[df_final['Risco Jur√≠dico'] == 'ALTO'])) + """
- **Risco M√©dio**: """ + str(len(df_final[df_final['Risco Jur√≠dico'] == 'M√âDIO'])) + """
- **Risco Baixo**: """ + str(len(df_final[df_final['Risco Jur√≠dico'] == 'BAIXO'])) + """

## üî¨ Metodologia Pipeline

1. **Embeddings Sem√¢nticos**: An√°lise contextual profunda
2. **Extra√ß√£o de Especifica√ß√µes**: Identifica√ß√£o autom√°tica de caracter√≠sticas t√©cnicas
3. **Matching Exato**: Correspond√™ncia direta de palavras-chave
4. **Scoring H√≠brido**: Combina√ß√£o ponderada de todas as t√©cnicas

---
*Relat√≥rio gerado com Pipeline Transformers para m√°xima precis√£o*
"""
        
        arquivo_md = pasta_saida / ("RELATORIO_PIPELINE_" + timestamp + ".md")
        with open(arquivo_md, 'w', encoding='utf-8') as f:
            f.write(resumo)
        
        print("‚úÖ Relat√≥rios gerados!")
        print("   üìÅ Pasta: " + str(pasta_saida))
        print("   üìÑ CSV Principal: RESULTADO_MATCHING_INTELIGENTE.csv")
        print("   üìä Excel Principal: RELATORIO_MATCHING_COMPLETO.xlsx")
        print("   üìÑ Pipeline CSV: " + arquivo_pipeline.name)
        print("   üìù Relat√≥rio: " + arquivo_md.name)
        print("   üí∞ Economia: R$ " + "{:,.2f}".format(economia_total))
        print("   üéØ Matches Excelentes: " + str(matches_excelentes))
        
        return True

def main():
    """Fun√ß√£o principal"""
    print("üéØ SISTEMA DE MATCHING COM PIPELINE TRANSFORMERS")
    print("=" * 70)
    print("Vers√£o: Pipeline Integrado | Data: " + datetime.now().strftime('%d/%m/%Y'))
    print("=" * 70)
    
    if not TRANSFORMERS_AVAILABLE:
        print("\n‚ùå ERRO: Transformers n√£o est√° instalado!")
        print("üì¶ Instale com: pip install transformers torch")
        print("üîÑ Ou use a vers√£o simplificada: matching_simples_corrigido.py")
        return
    
    # Executar
    matcher = MatchingComPipeline()
    
    try:
        if matcher.processar_tudo():
            if matcher.gerar_relatorios():
                print("\nüéâ SUCESSO! Pipeline executado com √™xito.")
                print("üìÅ Arquivos gerados na pasta de or√ßamentos")
                print("üöÄ Matching realizado com tecnologia de ponta!")
            else:
                print("\n‚ùå Erro na gera√ß√£o de relat√≥rios")
        else:
            print("\n‚ùå Erro no processamento")
    
    except Exception as e:
        print("\nüí• Erro: " + str(e))
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()


import pandas as pd
import re
import difflib
import os
import glob
import json
import numpy as np
import torch  # Dispon√≠vel no env
from sklearn.metrics.pairwise import cosine_similarity

# Embedding com torch pra sem√¢ntica assertiva
vocab_size = 1000  # Hash simples pra demo
embedding_dim = 50
embedding_matrix = torch.rand(vocab_size, embedding_dim)  # Random weights pra diversifica√ß√£o

def get_embedding(text):
    words = normalizar_texto(text).split()
    if not words:
        return np.zeros((1, embedding_dim))
    hashes = [hash(w) % vocab_size for w in words]
    vecs = embedding_matrix[hashes].numpy()
    vec = vecs.mean(axis=0, keepdims=True)
    return vec

def calcular_similaridade_embeddings(emb_edital, emb_produto):
    return cosine_similarity(emb_edital, emb_produto)[0][0] * 100

def normalizar_texto(texto):
    if not isinstance(texto, str):
        return ""
    texto = texto.lower()
    texto = re.sub(r"[^\w\s]", " ", texto)
    texto = re.sub(r"\s+", " ", texto)
    return texto.strip()

def extrair_categoria_edital(texto):
    match = re.search(r"(percurs√£o|sopro|piano|amplificador|mesa √°udio|microfone|caixa ac√∫stica|projetor|instrumento)", texto, re.I)
    return match.group(1).lower() if match else "geral"

def load_json_cats(json_path):
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            gov_reges = json.load(f)
        categorias = {}
        for item in gov_reges:
            tipo = item.get('carrinhoNome', '').lower().split('-')[-1].strip()
            termos = set(re.findall(r"\b\w{4,}\b", item.get('carrinhoCaracteristicas', '').lower()))
            categorias[tipo] = termos
        return categorias
    except Exception as e:
        print(f"Erro ao carregar JSON: {e}")
        return {}

def processar(edital_path, base_path, json_path, salvar_em=None):
    print(f"üîÅ Processando {edital_path} com torch embeddings e filtro JSON rigoroso...")

    categorias = load_json_cats(json_path)
    base_df = pd.read_excel(base_path)
    edital_df = pd.read_excel(edital_path)

    resultados = []
    matches = 0
    economia_total = 0.0

    for _, item in edital_df.iterrows():
        texto_edital = item["Item"]
        cat_edital = extrair_categoria_edital(texto_edital)
        termos_filtro = categorias.get(cat_edital, set())
        
        # Filtro rigoroso: Exige >=2 termos match
        filtered_base = base_df[base_df['Descri√ß√£o'].apply(lambda d: sum(t in normalizar_texto(d) for t in termos_filtro) >= 2)]
        if filtered_base.empty:
            filtered_base = base_df  # Fallback
        filtered_base = filtered_base.copy()
        filtered_base['random'] = np.random.rand(len(filtered_base))  # Variabilidade

        emb_edital = get_embedding(texto_edital)

        melhor_match = None
        melhor_score = 0.0
        melhor_preco = float('inf')
        score_emb = 0.0
        score_fuzzy = 0.0

        for _, produto in filtered_base.iterrows():
            texto_produto = produto["Descri√ß√£o"]
            emb_produto = get_embedding(texto_produto)
            score_emb_temp = calcular_similaridade_embeddings(emb_edital, emb_produto)
            score_fuzzy_temp = difflib.SequenceMatcher(None, texto_edital, texto_produto).ratio() * 100
            score = (score_emb_temp * 0.7) + (score_fuzzy_temp * 0.3)

            if score > melhor_score or (score == melhor_score and produto["Valor"] < melhor_preco):
                melhor_score = score
                melhor_match = produto
                melhor_preco = produto["Valor"]
                score_emb = score_emb_temp
                score_fuzzy = score_fuzzy_temp

        valor_ref_unit = item.get("Valor Unit√°rio (R$)", 0)
        qtd = item.get("Quantidade Total", 1)
        valor_ref_total = valor_ref_unit * qtd

        if melhor_score >= 70:  # Mais rigoroso pra evitar ruins
            matches += 1
            preco_fornecedor = melhor_match["Valor"] if melhor_match is not None else 0
            preco_disputa = preco_fornecedor * 1.53
            economia = max(0, valor_ref_total - (preco_disputa * qtd))
            economia_total += economia
            pode_substituir = "Sim"
            exige_impugnacao = "N√£o"
            obs_juridica = "Compat√≠vel com princ√≠pios de economicidade e isonomia (Lei 14.133/21)."
            comparacao = f"Semelhan√ßas: Torch embeddings {score_emb:.2f}% + Fuzzy {score_fuzzy:.2f}%, filtrado rigoroso por JSON cat '{cat_edital}' com termos {list(termos_filtro)[:5]}. Diferen√ßas: Sem√¢nticas m√≠nimas, diversificado por random."
        else:
            preco_fornecedor = 0
            preco_disputa = 0
            pode_substituir = "N√£o"
            exige_impugnacao = "Sim, aus√™ncia de equivalente."
            obs_juridica = "Buscar impugna√ß√£o para inclus√£o de equivalentes ou pesquisa de mercado. [N√£o Verificado]"
            comparacao = "Nenhum produto compat√≠vel ap√≥s filtro rigoroso JSON e embeddings."

        resultado = {
            "N√∫mero do Item": item.get("N√∫mero do Item", "N/A"),
            "Item do Edital": texto_edital,
            "Quantidade Total": qtd,
            "Valor Unit√°rio Edital (R$)": valor_ref_unit,
            "Valor Ref. Total": valor_ref_total,
            "Unidade de Fornecimento": item.get("Unidade de Fornecimento", "N/A"),
            "Intervalo M√≠nimo entre Lances (R$)": item.get("Intervalo M√≠nimo entre Lances (R$)", "N/A"),
            "Local de Entrega (Quantidade)": item.get("Local de Entrega (Quantidade)", "N/A"),
            "Marca": melhor_match["Marca"] if melhor_match is not None else "N/A",
            "Produto Sugerido": melhor_match["Item"] if melhor_match is not None else "N/A",
            "Descri√ß√£o do Produto": melhor_match["Descri√ß√£o"] if melhor_match is not None else "N/A",
            "Pre√ßo Fornecedor": preco_fornecedor,
            "Pre√ßo com Margem 53% (para Disputa)": preco_disputa,
            "Compara√ß√£o T√©cnica": comparacao,
            "% Compatibilidade": round(melhor_score, 2),
            "Pode Substituir?": pode_substituir,
            "Exige Impugna√ß√£o?": exige_impugnacao,
            "Observa√ß√£o Jur√≠dica": obs_juridica,
            "Estado": melhor_match["Estado"] if melhor_match is not None else "N/A",
            "Foto": melhor_match["Foto"] if melhor_match is not None else "N/A"
        }
        
        resultados.append(resultado)

    df_final = pd.DataFrame(resultados)
    
    if salvar_em:
        df_final.to_excel(salvar_em, index=False)
        print(f"‚úÖ Resultado salvo em: {salvar_em}")
    
    resumo = f"Resumo: Matches encontrados: {matches}, economia total estimada: {economia_total:.2f} (baseada no pre√ßo com margem vs. refer√™ncia)."
    print(resumo)
    
    return df_final

# Processar
if __name__ == "__main__":
    edital_dir = r"C:\Users\pietr\OneDrive\√Årea de Trabalho\ARTE\01_EDITAIS\ORCAMENTOS"
    base_path = r"C:\Users\pietr\OneDrive\√Årea de Trabalho\ARTE\01_EDITAIS\data_base.xlsx"
    json_path = r"C:\Users\pietr\.vscode\arte_\testes\gov_reges.json"
    xlsx_files = glob.glob(os.path.join(edital_dir, "*.xlsx"))
    
    for file in xlsx_files:
        try:
            salvar_em = os.path.join(edital_dir, f"{os.path.splitext(os.path.basename(file))[0]}_estudo.xlsx")
            resultado = processar(file, base_path, json_path, salvar_em)
            print(resultado.head())
        except Exception as e:
            print(f"Erro ao processar {file}: {e}")